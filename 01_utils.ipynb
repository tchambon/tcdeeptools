{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean():\n",
    "    gc.collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_minibatch(dl):\n",
    "    minibatch = next(iter(dl))\n",
    "    print(f'minibatch extracted. Shape: {minibatch.shape}')\n",
    "    return minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_files_dir(path, ext, debug=False):\n",
    "    items = []\n",
    "    for r, d, f in os.walk(path):\n",
    "            if debug: print(f'In directory {r}: {len(f)} files')\n",
    "            for file in f:\n",
    "                for e in ext:\n",
    "                    if e in file:\n",
    "                        items.append(r+'/'+file)\n",
    "                    if debug: print(f'working on img {path+file}')\n",
    "    return list(set(items))\n",
    "\n",
    "\n",
    "def get_name_training(prefix, placeholder=True, params={}):\n",
    "    id_training = get_id_training(placeholder=placeholder, params=params)\n",
    "    return f'{id_training}-{prefix}'\n",
    "\n",
    "\n",
    "def get_id_training(path='./svg', name='', placeholder=True, params={}):\n",
    "    files = get_files_dir(path, [''], debug=False)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for f in files:\n",
    "        try:\n",
    "            number = int(f.split('/')[-1].split('-')[0])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        if number > index:\n",
    "            index = number\n",
    "            \n",
    "    print(f'Biggest index = {index}, new index = {index+1}')\n",
    "    if placeholder:\n",
    "        with open(f'{path}/{index+1}-placeholder-{name}', 'w') as fp:\n",
    "            fp.write(f'{params}')\n",
    "    \n",
    "    \n",
    "    return index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def to_byte_tensor(item):\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))\n",
    "    w,h = item.size\n",
    "    return res.view(h,w,-1).permute(2,0,1)\n",
    "\n",
    "def to_float_tensor(item): return item.float().div_(255.)\n",
    "\n",
    "\n",
    "def normalize_tan(x):\n",
    "    return (x - 0.5) / 0.5\n",
    "\n",
    "def decode_from_tan(x):\n",
    "    return (x * 0.5) + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def loader(path, tfms, show_img=False):\n",
    "    style_im_raw = PIL.Image.open(path).convert('RGB')\n",
    "    if show_img:\n",
    "        plt.imshow(style_im_raw)\n",
    "    \n",
    "    im = tfms(style_im_raw)\n",
    "    \n",
    "    show_img_from_tensor(im)\n",
    "    return im.unsqueeze(0).cuda()\n",
    "\n",
    "def show_img_from_tensor(x, ax=None, decoder=None, figsize=(8,8), title=''):\n",
    "    if decoder is not None:\n",
    "        x = decoder(x)\n",
    "    img = x.detach().cpu().numpy().transpose((1,2,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if ax:\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        \n",
    "        if len(title) > 0:\n",
    "            fig.suptitle(title, y=0.9, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def gradient_flow(m):\n",
    "    mean_grad = []\n",
    "    std_grad = []\n",
    "    median_grad = []\n",
    "    norm_grad = []\n",
    "    names = []\n",
    "    for i, (n, p) in enumerate(m.named_parameters()):\n",
    "        if p.grad is not None and p.grad.ndimension() > 1 :\n",
    "            #print(n, p.grad.shape, p.grad.ndimension())\n",
    "            mean_grad.append(p.grad.mean())\n",
    "            std_grad.append(p.grad.std())\n",
    "            median_grad.append(p.grad.median())\n",
    "            norm_grad.append(p.grad.norm())\n",
    "            names.append(n.replace('layers', 'l'))\n",
    "    \n",
    "    return names, mean_grad, std_grad, median_grad, norm_grad\n",
    "\n",
    "def viz_grad_flow(names, mean_grad, std_grad, median_grad, norm_grad, target= 'Not specified'):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1,figsize=(15, 12))\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    axes[0].plot(names, mean_grad, c='r')\n",
    "    axes[0].plot(names, median_grad, c='b')\n",
    "    axes[1].plot(names, std_grad)\n",
    "    axes[2].plot(names, norm_grad)\n",
    "\n",
    "    \n",
    "    axes[0].set_title(f'Mean(R)/Med(B) {target}')\n",
    "    axes[1].set_title(f'Std {target}')\n",
    "    axes[2].set_title(f'Norm {target}')\n",
    "    \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OutputTrainingWidget:\n",
    "    def __init__(self, batch_size = 64, history_size=1):\n",
    "        self.display = widgets.Output(layout={'border': '1px solid black'})\n",
    "        self.batch_size = batch_size\n",
    "        self.nrow_batch = math.ceil(math.sqrt(self.batch_size))\n",
    "        self.history_size = history_size\n",
    "        self.current = 0\n",
    "        \n",
    "    def display_widget(self):\n",
    "        display(self.display)\n",
    "\n",
    "    def display_minibatch(self, minibatch, nb_iter=0, normalize=True):\n",
    "        self.current += 1\n",
    "        with self.display:\n",
    "            plt.figure(figsize=(20,20))\n",
    "            if self.history_size != -1 and self.current % self.history_size == 0:\n",
    "                clear_output()\n",
    "            print(f'Display minibatch for iter {nb_iter}')\n",
    "\n",
    "            ax = plt.gca()\n",
    "            \n",
    "            grid = torchvision.utils.make_grid(minibatch[:,:3,:,:], nrow=self.nrow_batch, normalize=normalize)\n",
    "            show_img_from_tensor(grid, ax = ax)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.utils.make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_tb_logdir(name):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    return 'logs/' + current_time + f'/{name}'\n",
    "\n",
    "def get_identity_training(name):\n",
    "    return f'{name}-{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    \n",
    "def get_tb_writer(name):\n",
    "\n",
    "    train_summary_writer = SummaryWriter(get_tb_logdir(name))\n",
    "    \n",
    "    return train_summary_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 02_training.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
